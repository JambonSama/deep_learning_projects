\section{Utilization}

To use the framework of this project to construct a neural network, the modules \mintinline{python}{neural_network} and \mintinline{python}{layer} have to be imported. 
Below is an example of use to create a neural network with $2$ inputs, $2$ outputs and $3$ hidden layers of $25$ neurons each with TanH layers (the module \mintinline{python}{neural_network} is imported as \mintinline{python}{nn}):

\begin{minted}{python}
net = nn.NeuralNetwork()
net.sequential(layer.TanH(2,25), layer.TanH(25,25), layer.TanH(25,25), layer.TanH(25,2))
net.train_network(train_set, train_label, epochs=100, batch_size=1, learning_rate=0.02, print_error=True, 
						test_set=test_set, test_label=test_label)
\end{minted}

The first step is to create a neural network with \mintinline{python}{NeuralNetwork()}, and then to parametrize it with the required layers with \mintinline{python}{sequential(layer.<layer_type>(nb_input_layer, nb_output_layer), ...)}. 
Then the neural network is ready to be trained. 
To train the neural network, the function \mintinline{python}{train_network()} is called. If the \mintinline{python}{print_error} is set to \mintinline{python}{False}, the \mintinline{python}{test_set} and \mintinline{python}{test_label} are not needed. 
Thus, the train function will not compute the error for each epochs. It is important to note that there are no protections for wrong inputs in this function. The user is responsible for providing a correct input: the train set and test set have to be coherent with the neural network architecture, and the batch size has to be a divisor of the train set size.

After the training, the user can use the neural network with the function \mintinline{python}{run(input)} and can access different logs: the log of the loss with \mintinline{python}{net.graph_loss} and if \mintinline{python}{print_error=True} the log of the loss and the accuracy with \mintinline{python}{net.logs}.
They can also see the parameters of the neural network by using the function \mintinline{python}{net.params()}.

\subsection{New layers}

With the chosen implementation, it is easy to implement new type of layers. To do so, the user has to create a new derived class from \mintinline{python}{Linear} and overload the constructor (in order to initialize differently the weight and bias matrix), the activation function and the derivative function with the new function for the layer. 
