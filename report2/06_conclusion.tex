\section{Conclusion}
In this project, a framework for simple neural network was developed with the possibility to construct neural network  with none-fixed number of fully connected Linear, ReLu or TanH layer. It use the stochastic gradient descent with the mean square error as a loss function to train the neural network. It can also use the batch gradient descent, if batch size is set.

A improvement to this framework would be to implement a better gradient descent with matrix multiplication so that the backward pass can take as input the result  